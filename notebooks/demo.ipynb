{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b5a0dd-310c-4c46-b8a1-b90627c3bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', 2000)\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.max_columns = 200\n",
    "np.set_printoptions(linewidth=500)\n",
    "pd.set_option(\"max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from minigpt4.common.config import Config\n",
    "from minigpt4.common.dist_utils import get_rank\n",
    "from minigpt4.common.registry import registry\n",
    "from minigpt4.conversation.conversation import Chat, CONV_VISION\n",
    "\n",
    "\n",
    "# imports modules for registration\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Demo\")\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\"--gpu-id\", type=int, default=0, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "             \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "             \"change to --cfg-options instead.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "\n",
    "# ========================================\n",
    "#             Model Initialization\n",
    "# ========================================\n",
    "\n",
    "print('Initializing Chat')\n",
    "args = parse_args()\n",
    "cfg = Config(args)\n",
    "\n",
    "model_config = cfg.model_cfg\n",
    "model_config.device_8bit = args.gpu_id\n",
    "model_cls = registry.get_model_class(model_config.arch)\n",
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "\n",
    "vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n",
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))\n",
    "print('Initialization Finished')\n",
    "\n",
    "\n",
    "# ========================================\n",
    "#             Gradio Setting\n",
    "# ========================================\n",
    "\n",
    "def gradio_reset(chat_state, img_list):\n",
    "    if chat_state is not None:\n",
    "        chat_state.messages = []\n",
    "    if img_list is not None:\n",
    "        img_list = []\n",
    "    return None, gr.update(value=None, interactive=True), gr.update(placeholder='Please upload your image first',\n",
    "                                                                    interactive=False), gr.update(\n",
    "        value=\"Upload & Start Chat\", interactive=True), chat_state, img_list\n",
    "\n",
    "\n",
    "def upload_img(gr_img, text_input, chat_state):\n",
    "    if gr_img is None:\n",
    "        return None, None, gr.update(interactive=True), chat_state, None\n",
    "    chat_state = CONV_VISION.copy()\n",
    "    img_list = []\n",
    "    llm_message = chat.upload_img(gr_img, chat_state, img_list)\n",
    "    return gr.update(interactive=False), gr.update(interactive=True, placeholder='Type and press Enter'), gr.update(\n",
    "        value=\"Start Chatting\", interactive=False), chat_state, img_list\n",
    "\n",
    "\n",
    "def gradio_ask(user_message, chatbot, chat_state):\n",
    "    if len(user_message) == 0:\n",
    "        return gr.update(interactive=True, placeholder='Input should not be empty!'), chatbot, chat_state\n",
    "    chat.ask(user_message, chat_state)\n",
    "    chatbot = chatbot + [[user_message, None]]\n",
    "    return '', chatbot, chat_state\n",
    "\n",
    "\n",
    "def gradio_answer(chatbot, chat_state, img_list, num_beams, temperature):\n",
    "    llm_message = chat.answer(conv=chat_state,\n",
    "                              img_list=img_list,\n",
    "                              num_beams=num_beams,\n",
    "                              temperature=temperature,\n",
    "                              max_new_tokens=300,\n",
    "                              max_length=2000)[0]\n",
    "    chatbot[-1][1] = llm_message\n",
    "    return chatbot, chat_state, img_list\n",
    "\n",
    "\n",
    "title = \"\"\"<h1 align=\"center\">Demo of MiniGPT-4</h1>\"\"\"\n",
    "description = \"\"\"<h3>This is the demo of MiniGPT-4. Upload your images and start chatting!</h3>\"\"\"\n",
    "article = \"\"\"<p><a href='https://minigpt-4.github.io'><img src='https://img.shields.io/badge/Project-Page-Green'></a></p><p><a href='https://github.com/Vision-CAIR/MiniGPT-4'><img src='https://img.shields.io/badge/Github-Code-blue'></a></p><p><a href='https://raw.githubusercontent.com/Vision-CAIR/MiniGPT-4/main/MiniGPT_4.pdf'><img src='https://img.shields.io/badge/Paper-PDF-red'></a></p>\n",
    "\"\"\"\n",
    "\n",
    "# TODO show examples below\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(title)\n",
    "    gr.Markdown(description)\n",
    "    gr.Markdown(article)\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=0.5):\n",
    "            image = gr.Image(type=\"pil\")\n",
    "            upload_button = gr.Button(value=\"Upload & Start Chat\", interactive=True, variant=\"primary\")\n",
    "            clear = gr.Button(\"Restart\")\n",
    "\n",
    "            num_beams = gr.Slider(\n",
    "                minimum=1,\n",
    "                maximum=10,\n",
    "                value=1,\n",
    "                step=1,\n",
    "                interactive=True,\n",
    "                label=\"beam search numbers)\",\n",
    "            )\n",
    "\n",
    "            temperature = gr.Slider(\n",
    "                minimum=0.1,\n",
    "                maximum=2.0,\n",
    "                value=1.0,\n",
    "                step=0.1,\n",
    "                interactive=True,\n",
    "                label=\"Temperature\",\n",
    "            )\n",
    "\n",
    "        with gr.Column():\n",
    "            chat_state = gr.State()\n",
    "            img_list = gr.State()\n",
    "            chatbot = gr.Chatbot(label='MiniGPT-4')\n",
    "            text_input = gr.Textbox(label='User', placeholder='Please upload your image first', interactive=False)\n",
    "\n",
    "    upload_button.click(upload_img, [image, text_input, chat_state],\n",
    "                        [image, text_input, upload_button, chat_state, img_list])\n",
    "\n",
    "    text_input.submit(gradio_ask, [text_input, chatbot, chat_state], [text_input, chatbot, chat_state]).then(\n",
    "        gradio_answer, [chatbot, chat_state, img_list, num_beams, temperature], [chatbot, chat_state, img_list]\n",
    "    )\n",
    "    clear.click(gradio_reset, [chat_state, img_list], [chatbot, image, text_input, upload_button, chat_state, img_list],\n",
    "                queue=False)\n",
    "\n",
    "gr.blocks.networking.url_ok = lambda _: True\n",
    "demo.launch()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726af87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
